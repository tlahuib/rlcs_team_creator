{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "import utils\n",
    "\n",
    "reg = pickle.load(open('LR.pkl', 'rb'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Elo Theory\n",
    "\n",
    "The basic idea is that a team $X$ has a rating $R_X$. These ratings can help us calculate the expected result that a given team, say $A$, will beat another team, say $B$:\n",
    "\n",
    "$ \\begin{align}\n",
    "    \\nonumber \\bar{E}[A \\text{ beats } B] &= \\bar{E}_{A, B} \\\\\n",
    "    \\nonumber &= \\frac{1}{1 + 10^{(R_B - R_A) / 400}}\n",
    "\\end{align} $\n",
    "\n",
    "Now, this formula is actually an estimation of the expected value. We can not know the actual value and that is why we need the ratings in the first place. As such, we need to update the ratings (and their inherent probabilities) everytime we actually observe a match between $A$ and $B$. Assume that we observed said match, and let us denote the score outcome from the viewpoint of $A$ as $S_A$. $S_A$ will be $1$ if $A$ won, and $0$ if $A$ lost and $1/2$ if they tied. Similarly, from the viewpoint of $B$, $S_B$ is $1$ if $B$ won, $0$ if they lost and $1/2$ if they tied. Let us observe what happens when we express the expectation as its original probabillistic definition:\n",
    "\n",
    "$ \\begin{align}\n",
    "    \\nonumber \\bar{E}_{A, B} = 1 \\cdot \\bar{P}(A \\text{ beats } B) + 1/2 \\cdot \\bar{P}(A \\text{ ties with } B) + 0 \\cdot \\bar{P}(A \\text{ loses to } B)\n",
    "\\end{align} $\n",
    "\n",
    "We can't know each individal probability in this context. However, if our game has no ties, we can simplify this expression to:\n",
    "\n",
    "$ \\begin{align}\n",
    "    \\nonumber \\bar{E}_{A, B} &= \\bar{P}(A \\text{ beats } B) \\\\\n",
    "    \\nonumber &= \\bar{P}_{A, B}\n",
    "\\end{align} $\n",
    "\n",
    "This means that, for games with only win/lose results, the Elo system actually approximates win probabilities. This interpretation will be useful in the future to test the performance of the system. \n",
    "\n",
    "Now, as we are talking about approximations, we need a way to update them with new observed matches. The original method uses a parameter $k$ for the update.\n",
    "\n",
    "$ \\begin{align}\n",
    "    \\nonumber R_{A, n + 1} = R_{A, n} + k \\cdot (S_{A, B} - \\bar{P}_{A, B})\n",
    "\\end{align} $"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Update problem\n",
    "\n",
    "The issue with the vanilla implementation is that it has no way of recognizing when the ratings (and implicitly the underlying aproximated probabilities) are too different from the real values. Neither has it the ability to react to the size of this difference, as the update parameter $k$ is assumed constant. Let us run some tests on the number of games to convergence and the distribution of the difference after convergence.\n",
    "\n",
    "First, we need to agree on what we mean by \"convergence\". Say we have the distribution for $D_{A, B}(n) = |P_{A, B}(n) - \\bar{P}_{A, B}(n)|$. Integrating the match number $n$ into the equation allows both the actual probabilities and the approximations to change through time, which is a healthy assumption as teams can train and hone their abilities. We can then define the convergence $C_{A, B}$ as:\n",
    "\n",
    "$ \\begin{align}\n",
    "    \\nonumber C_{A, B}(N) = \\sum_{n=0}^N w(n) \\cdot F_{D_{A, B}(n)}^{-1}(1/2)\n",
    "\\end{align} $\n",
    "\n",
    "It looks scary, but is quite simple. $F_{D_{A, B}(n)}^{-1}(1/2)$ denotes the median (or $50\\%$ quantile) of $D_{A, B}(n)$. We do this because we want something stable on which to measure convergence. The next step is to measure the rate of change of this median as we step further into the games, thus we wight the median according to $n$. We want to tune $w(n)$ such that it gives more importance to bigger $n$'s, which we assume would have converged better than smaller ones.\n",
    "\n",
    "Let us see how this works if $F_{D_{A, B}(n)}^{-1}(1/2) = e^{-n / 100} + 0.2$ and $w(n) = \\frac{e^\\frac{-5n}{N}}{\\sum_{k=0}^N e^\\frac{-5k}{N}}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 1000\n",
    "n = np.array(list(range(N)))\n",
    "median = np.e ** (-n / 100) + 0.2\n",
    "\n",
    "fig = go.Figure(layout=utils.layout_dict | dict(\n",
    "    title='Convergence example', \n",
    "    legend=dict(x=0.8, bgcolor=utils.background_color), \n",
    "    xaxis=dict(title='n')\n",
    "))\n",
    "\n",
    "# Plot the median\n",
    "fig.add_trace(go.Scatter(x=n, y=median, name='Median of the Difference'))\n",
    "\n",
    "# Plot convergenve value\n",
    "weights = np.e ** -np.linspace(5, 0, N)\n",
    "weights /= sum(weights)\n",
    "convergence = sum(median * weights)\n",
    "fig.add_trace(go.Scatter(x=n, y=[convergence] * N, name='Convergence Value'))\n",
    "\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that our method is a fairly good approximation, but it still needs to be tested against $N$ to see how it behaves. Fortunately, we know that our choice for the median converges to $0.2$, so we can observe how we reach that value for each increasing choice of $N$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "convergence = []\n",
    "Ns = list(range(50, 10000, 50))\n",
    "for N in Ns:\n",
    "    # Setup median\n",
    "    n = np.array(list(range(N)))\n",
    "    median = np.e ** (-n / 100) + 0.2\n",
    "\n",
    "    # Calculate convergence value\n",
    "    weights = np.e ** -np.linspace(5, 0, N)\n",
    "    weights /= sum(weights)\n",
    "    convergence.append(sum(median * weights))\n",
    "\n",
    "# Plot results\n",
    "fig = go.Figure(layout=utils.layout_dict | dict(\n",
    "    title='Convergence Sensitivity to N', \n",
    "    legend=dict(x=0.8, bgcolor=utils.background_color), \n",
    "    xaxis=dict(title='N')\n",
    "))\n",
    "\n",
    "fig.add_trace(go.Scatter(x=Ns, y=convergence, name='Approximated Convergence Values'))\n",
    "fig.add_trace(go.Scatter(x=Ns, y=[0.2] * len(Ns), name='Actual Convergence at Limit'))\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convergence Tests\n",
    "\n",
    "Let $P_{A, B}(n) = BRW_{0.25, 0, 0.01}(n)$, where $BRW_{\\beta, \\mu, \\sigma}$ is a Bounded Random Walk with initial value $BRW_{\\beta, \\mu, \\sigma}(0) = \\beta$, drift $\\mu$ and standard deviation $\\sigma$. We first need a function to generate the ratings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_elo_2_players(games_results: np.array, k=1):\n",
    "    # Get shapes\n",
    "    N = games_results.shape\n",
    "    Sa = games_results.copy()\n",
    "\n",
    "    # Calculate Ratings\n",
    "    Ra = np.zeros(N)\n",
    "    pa = np.zeros(N)\n",
    "    pa[0] += 1/2\n",
    "    for i in range(1, N[0]):\n",
    "        # Update rating\n",
    "        Ra[i] = Ra[i-1] + k * (Sa[i - 1] - pa[i - 1])\n",
    "\n",
    "        # Update Approx Probabilities\n",
    "        pa[i] = 1 / (1 + 10 ** (-2 * Ra[i] / 400))\n",
    "\n",
    "    return Ra, pa"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And see how $D_{A, B}(n)$ behaves under this test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example for k=1\n",
    "N = [500, 500]\n",
    "p = utils.non_stationary_bounded_random_walk(initial=1/4, size=N)\n",
    "games_results = (np.random.random(N) <= p).astype(int)\n",
    "\n",
    "Ra, pa = calculate_elo_2_players(games_results)\n",
    "\n",
    "diff = abs(p - pa)\n",
    "quantiles = np.quantile(diff, [0.1, 0.5, 0.9], axis=1)\n",
    "\n",
    "# Calculate convergence value\n",
    "weights = np.e ** -np.linspace(5, 0, N[0])\n",
    "weights /= sum(weights)\n",
    "converge_value = sum(quantiles[1] * weights)\n",
    "\n",
    "# Plot example\n",
    "x_range = list(range(N[0])) + list(reversed(range(N[0])))\n",
    "\n",
    "fig = go.Figure(layout=utils.layout_dict | dict(title='Example of D(n) for k=1'))\n",
    "\n",
    "fig.add_trace(go.Scatter(\n",
    "        x = x_range, y=list(quantiles[2]) + list(quantiles[0][::-1]), fill='toself', mode='none',\n",
    "        hoveron='points', fillcolor='lightblue', name=f'80% CI', opacity=0.5\n",
    "    ))\n",
    "fig.add_trace(go.Scatter(y=quantiles[1], line=dict(color='lightblue'), name='Median'))\n",
    "fig.add_trace(go.Scatter(y=[converge_value] * N[0], line=dict(color='red'), name='Convergence Value'))\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see the output is quite noisy. This means that we need to increase the size of $N$, meaning both the number of games $N[0]$ and the number of parallel iterations $N[1]$. Let us investigate how the convergence values change with different $N$ and $k$ to choose the correct setup for the test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_convergence(N, initial, K):\n",
    "    # Run games\n",
    "    p = utils.non_stationary_bounded_random_walk(initial = initial, size=N)\n",
    "    games_results = (np.random.random(N) <= p).astype(int)\n",
    "\n",
    "    convergence_values = []\n",
    "    for k in K:\n",
    "        # Approximated probabilities\n",
    "        _, pa = calculate_elo_2_players(games_results, k=k)\n",
    "\n",
    "        # Calculate difference and median\n",
    "        diff = abs(p - pa)\n",
    "        median = np.quantile(diff, 0.5, axis=1)\n",
    "\n",
    "        # Calculate convergence value\n",
    "        weights = np.e ** -np.linspace(5, 0, N[0])\n",
    "        weights /= sum(weights)\n",
    "        convergence_values.append(sum(median * weights))\n",
    "\n",
    "    return convergence_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = [1, 2, 5, 7, 10, 20, 50, 100, 1000]\n",
    "convergence_values = []\n",
    "N0s = [100, 500, 1000, 2000, 3000, 5000, 10000]\n",
    "for N0 in N0s:\n",
    "    N = [N0, 3000]\n",
    "    convergence_values += [calculate_convergence(N, 1/4, K)]\n",
    "\n",
    "convergence_values = np.array(convergence_values).T\n",
    "\n",
    "fig = go.Figure(layout=utils.layout_dict)\n",
    "\n",
    "for i in range(len(K)):\n",
    "    fig.add_trace(go.Scatter(x=N0s, y=convergence_values[i], name=f'k = {K[i]}'))\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = [1, 2, 5, 7, 10, 20, 50, 100, 1000]\n",
    "convergence_values = []\n",
    "N1s = [100, 500, 1000, 2000, 3000, 5000, 10000]\n",
    "for N1 in N1s:\n",
    "    N = [3000, N1]\n",
    "    convergence_values += [calculate_convergence(N, 1/4, K)]\n",
    "\n",
    "convergence_values = np.array(convergence_values).T\n",
    "\n",
    "fig = go.Figure(layout=utils.layout_dict)\n",
    "\n",
    "for i in range(len(K)):\n",
    "    fig.add_trace(go.Scatter(x=N0s, y=convergence_values[i], name=f'k = {K[i]}'))\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It appears that $N = [3000, 3000]$ is a good choice for up to $k = 1,000$."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now for the actual test. It will measure $C_{A, B}$ and the size of the $80\\%$ Central Interval (CI) on $D_{A, B}(n)$ for different values of $k$. To test for the convergence value, we will actually look for\n",
    "\n",
    "$ \\begin{align}\n",
    "    \\nonumber Cn_{A, B}(N) = \\argmin_n \\left[ \\left| F_{D_{A, B}(n)}^{-1}(1/2) - C_{A, B} \\right| \\leq 1\\% \\right]\n",
    "\\end{align} $\n",
    "\n",
    "That is, the first game in which the median of $D_{A, B}(n)$ is less than $1\\%$ away from the convergence value. This will tell us how many games it took to reach convergence. Let's look at the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run games\n",
    "N = [3000, 3000]\n",
    "p = utils.non_stationary_bounded_random_walk(initial = 1/4, size=N)\n",
    "games_results = (np.random.random(N) <= p).astype(int)\n",
    "\n",
    "time2convergence = []\n",
    "convergence_values = []\n",
    "ci = []\n",
    "K = list(range(1, 11))\n",
    "K = K + [k * 10 for k in K] #+ [k * 100 for k in K] + [1000]\n",
    "for k in K:\n",
    "    # Approximated probabilities\n",
    "    _, pa = calculate_elo_2_players(games_results, k=k)\n",
    "\n",
    "    # Calculate difference and median\n",
    "    diff = abs(p - pa)\n",
    "    quantiles = np.quantile(diff, [0.1, 0.5, 0.9], axis=1)\n",
    "    median = quantiles[1]\n",
    "    central_interval = quantiles[2] - quantiles[0]\n",
    "\n",
    "    # Calculate convergence value\n",
    "    weights = np.e ** -np.linspace(5, 0, N[0])\n",
    "    weights /= sum(weights)\n",
    "    convergence_value = sum(median * weights)\n",
    "    first_convergence = np.argmax(abs(median - converge_value) <= 0.01)\n",
    "\n",
    "    # Fill CI and time to convergence\n",
    "    time2convergence.append(first_convergence)\n",
    "    convergence_values.append(convergence_value)\n",
    "    ci.append(central_interval[first_convergence:].mean())\n",
    "\n",
    "# Draw a nice plot\n",
    "fig = make_subplots(specs=[[{\"secondary_y\": True}]])\n",
    "\n",
    "fig.add_trace(go.Scatter(x=K, y=time2convergence, name='Time to Convergence', mode='lines'), secondary_y=False)\n",
    "fig.add_trace(go.Scatter(x=K, y=convergence_values, name='Convergence Value', mode='lines'), secondary_y=True)\n",
    "fig.add_trace(go.Scatter(x=K, y=ci, name='Size of 80%CI', mode='lines'), secondary_y=True)\n",
    "\n",
    "fig.update_layout(**utils.layout_dict)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example for k=20\n",
    "N = [5000, 1000]\n",
    "p = utils.non_stationary_bounded_random_walk(initial = 1/4, size=N)\n",
    "games_results = (np.random.random(N) <= p).astype(int)\n",
    "\n",
    "Ra, pa = calculate_elo_2_players(games_results, k=20)\n",
    "\n",
    "diff = abs(p - pa)\n",
    "quantiles = np.quantile(diff, [0.1, 0.5, 0.9], axis=1)\n",
    "\n",
    "# Calculate convergence value\n",
    "weights = np.e ** -np.linspace(5, 0, N[0])\n",
    "weights /= sum(weights)\n",
    "converge_value = sum(quantiles[1] * weights)\n",
    "first_convergence = np.argmax(abs(quantiles[1] - converge_value) <= 0.01)\n",
    "\n",
    "# Print results\n",
    "central_interval = quantiles[2] - quantiles[0]\n",
    "print(f'Time to convergence: {first_convergence}')\n",
    "print(f'Convergence Value: {converge_value: .2f}')\n",
    "print(f'80% CI: {central_interval[first_convergence:].mean()}')\n",
    "\n",
    "# Plot example\n",
    "l = 1\n",
    "x = int(N[0] / l)\n",
    "x_range = list(range(x)) + list(reversed(range(x)))\n",
    "\n",
    "fig = go.Figure(layout=utils.layout_dict | dict(title='Example of D(n) for k=20'))\n",
    "\n",
    "fig.add_trace(go.Scatter(\n",
    "        x = x_range, y=list(quantiles[2][::l]) + list(quantiles[0][::-l]), fill='toself', mode='none',\n",
    "        hoveron='points', fillcolor='lightblue', name=f'80% CI', opacity=0.5\n",
    "    ))\n",
    "fig.add_trace(go.Scatter(y=quantiles[1][::l], line=dict(color='lightblue'), name='Median'))\n",
    "fig.add_trace(go.Scatter(y=[converge_value] * x, line=dict(color='red'), name='Convergence Value'))\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Improving on Elo updates\n",
    "\n",
    "To no ones surprise, you either have to choose between fast convergence (a low time to convergence) or a stable convergence (small $80\\%$ CI). This is the issue with choosing a static $k$. However, we can tweak $k$ a bit to compensate for this by somehow leveraging our best guess of where we are situated in the convergence process. In simplified terms, we want $k$ to be larger when we have not achieved convergence, and gradually decrease in size until we reach convergence.\n",
    "\n",
    "We cannot asume that our stochastic process is stationary, thus we cannot state a minimum $k$ for convergence as the variance of the process may change in the future. What we can actually do is perform an approximation of the underlying probabilities, and then vary $k$ depending on how different our current ratings are from that approximation."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Probability approximation\n",
    "\n",
    "We will have to put a bit of effort into this approximation, as we will try to approximate probabilities based only on boolean observations. Extra care will be needed so we don't over-estimate the variance of the process and end up having a highly volatile approximation, or not enough adaptability. Let us observe the classical empiric mean formula\n",
    "\n",
    "$ \\begin{align}\n",
    "    \\nonumber &\\bar{E}[X] = \\sum_{n=1}^{N} \\frac{x_n}{N} = \\mu\n",
    "\\end{align} $\n",
    "\n",
    "We can run a little experiment, running this formula on the boolean results of a non-stationary process and observing how it behaves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = [1000, 1]\n",
    "\n",
    "# Simulate probabilities\n",
    "p = utils.non_stationary_bounded_random_walk(size=N, std=0.002, initial=1/4)\n",
    "p = p.flatten()\n",
    "\n",
    "# Simulate Games\n",
    "games_results = (np.random.random(N[0]) <= p).astype(int)\n",
    "\n",
    "# Calculate cummulative mean\n",
    "empiric_mean = games_results.cumsum() / np.linspace(1, N[0], N[0])\n",
    "\n",
    "\n",
    "# Draw a nice plot\n",
    "fig = go.Figure(layout=utils.layout_dict | dict(title='Empiric Mean on Non-Stationary process'))\n",
    "\n",
    "fig.add_trace(go.Scatter(y=p, name='Real Probabilities'))\n",
    "fig.add_trace(go.Scatter(y=empiric_mean, name='Empiric Mean'))\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The empiric formulas are highly sensitive in the first games, and then start losing this sensitivity to become quite flat at the end. Given the ever changing nature of the underlying problem, we need to modify the formulas to give more weight to more recent observations. A simple way of doing this is as follows\n",
    "\n",
    "$ \\begin{align}\n",
    "    \\nonumber &\\bar{E}_X(n) = \\alpha \\cdot \\bar{E}_X(n - 1) + (1 - \\alpha) \\cdot x_n = \\bar{\\mu}_X(n) \n",
    "\\end{align} $\n",
    "\n",
    "We can also initialize the values on $\\bar{E}_X(0) = 1/2$. We can call this a step-size mean and denote it by $\\bar{E}_{X, \\alpha}(0)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 1000\n",
    "\n",
    "# Simulate probabilities\n",
    "p = utils.non_stationary_bounded_random_walk(size=N, std=0.002, initial=1/4)\n",
    "\n",
    "# Simulate Games\n",
    "games_results = (np.random.random(N) <= p).astype(int)\n",
    "\n",
    "# Calculate cummulative mean and std\n",
    "alphas = np.array([0.85, 0.875, 0.9, 0.925, 0.95, 0.975, 0.99])\n",
    "means = []\n",
    "\n",
    "for i in range(len(alphas)):\n",
    "    means.append(utils.step_mean(games_results, alphas[i]))\n",
    "\n",
    "\n",
    "# Draw a nice plot\n",
    "fig = go.Figure(layout=utils.layout_dict | dict(title='Step-size Mean on Non-Stationary process', legend=dict(x=1)))\n",
    "\n",
    "fig.add_trace(go.Scatter(y=p, name='Real Probabilities'))\n",
    "\n",
    "for i in range(len(alphas)):\n",
    "    fig.add_trace(go.Scatter(y=means[i], name=f'Step-size Mean \\u03b1 = {alphas[i]}', opacity=0.2))\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another way to approach the means is by creating a window around our desired value, and computing the mean. This will allow us to compensate for any variability in the procecess and adjust accordinggly. Let us say we have a window of size $w$. Our window mean would be computed as:\n",
    "\n",
    "$$\n",
    "    \\bar{E}_{X, w}(n) = \\sum_{i = \\max{(0, n - w)}}^{\\min{(N, n + w)}} \\frac{x_i}{2 w}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 1000\n",
    "\n",
    "# Simulate probabilities\n",
    "p = utils.non_stationary_bounded_random_walk(size=N, std=0.002, initial=1/4)\n",
    "\n",
    "# Simulate Games\n",
    "games_results = (np.random.random(N) <= p).astype(int)\n",
    "\n",
    "# Calculate cummulative mean and std\n",
    "windows = np.array([5, 10, 20, 50, 100])\n",
    "means = []\n",
    "\n",
    "for i in range(len(windows)):\n",
    "    means.append(utils.apply_rolling_function(games_results, windows[i], np.mean))\n",
    "\n",
    "\n",
    "# Draw a nice plot\n",
    "fig = go.Figure(layout=utils.layout_dict | dict(title='Window Mean on Non-Stationary process', legend=dict(x=1)))\n",
    "\n",
    "fig.add_trace(go.Scatter(y=p, name='Real Probabilities'))\n",
    "\n",
    "for i in range(len(windows)):\n",
    "    fig.add_trace(go.Scatter(y=means[i], name=f'Empiric Window w = {windows[i]}', opacity=0.2))\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we need a way to combine all the different means into a single output. I trained a simple Linear Regression model in this [notebook](2-teams_model_testing.ipynb) with the following inputs:\n",
    "\n",
    "- The game number (we are more uncertain in the beginning of the series).\n",
    "- The boolean results of the games.\n",
    "- Window mean and stds for $w \\in (5, 10, 20, 50, 100)$.\n",
    "- Step-size mean and stds for $\\alpha  \\in (0.85, 0.9, 0.95, 0.975, 0.99)$.\n",
    "\n",
    "This are the results on the same test framework as vanilla Elo updates.    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_elo_2_players_improved(games_results: np.array, reg=reg):\n",
    "    shape = list(reversed(games_results.shape))\n",
    "\n",
    "    X = utils.generate_X(games_results).T\n",
    "    pa = reg.predict(X).reshape(shape).T\n",
    "\n",
    "    return pa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = [5000, 1000]\n",
    "p = utils.non_stationary_bounded_random_walk(initial = 1/4, size=N)\n",
    "games_results = (np.random.random(N) <= p).astype(int)\n",
    "\n",
    "pa = calculate_elo_2_players_improved(games_results)\n",
    "\n",
    "diff = abs(p - pa)\n",
    "quantiles = np.quantile(diff, [0.1, 0.5, 0.9], axis=1)\n",
    "\n",
    "# Calculate convergence value\n",
    "weights = np.e ** -np.linspace(5, 0, N[0])\n",
    "weights /= sum(weights)\n",
    "converge_value = sum(quantiles[1] * weights)\n",
    "first_convergence = np.argmax(abs(quantiles[1] - converge_value) <= 0.01)\n",
    "\n",
    "# Print results\n",
    "central_interval = quantiles[2] - quantiles[0]\n",
    "print(f'Time to convergence: {first_convergence}')\n",
    "print(f'Convergence Value: {converge_value: .2f}')\n",
    "print(f'80% CI: {central_interval[first_convergence:].mean()}')\n",
    "\n",
    "# Plot example\n",
    "l = 1\n",
    "x = int(N[0] / l)\n",
    "x_range = list(range(x)) + list(reversed(range(x)))\n",
    "\n",
    "fig = go.Figure(layout=utils.layout_dict | dict(title='Improved Convergence Method'))\n",
    "\n",
    "fig.add_trace(go.Scatter(\n",
    "        x = x_range, y=list(quantiles[2][::l]) + list(quantiles[0][::-l]), fill='toself', mode='none',\n",
    "        hoveron='points', fillcolor='lightblue', name=f'80% CI', opacity=0.5\n",
    "    ))\n",
    "fig.add_trace(go.Scatter(y=quantiles[1][::l], line=dict(color='lightblue'), name='Median'))\n",
    "fig.add_trace(go.Scatter(y=[converge_value] * x, line=dict(color='red'), name='Convergence Value'))\n",
    "\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8f47c651d242aed6e4ae7e534134112b2b81aa4f276da1af63f964daf1b6e7e6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
